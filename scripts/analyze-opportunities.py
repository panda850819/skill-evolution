#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Skill Evolution - æ©Ÿæœƒåˆ†æè…³æœ¬

ç”¨é€”ï¼šåˆ†æ skill ä½¿ç”¨æ•¸æ“šï¼Œè­˜åˆ¥æ”¹é€²æ©Ÿæœƒï¼Œç”Ÿæˆæ¼”é€²ææ¡ˆ
è§¸ç™¼ï¼šæ‰‹å‹•åŸ·è¡Œæˆ–æ’ç¨‹

ä½¿ç”¨æ–¹å¼ï¼š
    python3 analyze-opportunities.py                    # åˆ†ææ‰€æœ‰ skills
    python3 analyze-opportunities.py --skill pine-lead  # åˆ†æç‰¹å®š skill
    python3 analyze-opportunities.py --days 7           # åˆ†ææœ€è¿‘ 7 å¤©
    python3 analyze-opportunities.py --report           # ç”Ÿæˆé€±å ±
"""

import json
import yaml
import re
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field, asdict
from collections import defaultdict
import hashlib

# === é…ç½® ===
HOME = Path.home()
EVOLUTION_DIR = HOME / ".claude" / "evolution"
SKILLS_DIR = HOME / ".claude" / "skills"
LOGS_DIR = EVOLUTION_DIR / "logs"
PENDING_DIR = EVOLUTION_DIR / "pending"
REPORTS_DIR = EVOLUTION_DIR / "reports"
BACKUPS_DIR = EVOLUTION_DIR / "backups"
CONFIG_DIR = HOME / ".claude" / "skills" / "skill-evolution" / "config"

# æ™‚å€è¨­å®šï¼ˆUTC+8ï¼‰
TZ_OFFSET = "+08:00"


# === æ•¸æ“šæ¨¡å‹ ===

@dataclass
class SkillMetrics:
    """Skill ä½¿ç”¨çµ±è¨ˆ"""
    skill_name: str
    invocation_count: int = 0
    success_count: int = 0
    failure_count: int = 0
    skip_count: int = 0
    avg_duration_ms: float = 0.0
    last_invoked: Optional[str] = None
    error_patterns: List[str] = field(default_factory=list)
    trigger_attempts: List[str] = field(default_factory=list)

    @property
    def success_rate(self) -> float:
        if self.invocation_count == 0:
            return 0.0
        return self.success_count / self.invocation_count * 100


@dataclass
class EvolutionProposal:
    """æ¼”é€²ææ¡ˆ"""
    proposal_id: str
    skill_id: str
    created_at: str
    expires_at: str
    change_level: str  # patch, minor, major
    status: str  # pending, approved, rejected, applied

    source_type: str
    source_session_id: Optional[str]
    source_trigger: str

    title: str
    description: str
    changes: List[Dict[str, Any]]
    impact: List[str]

    backup_path: Optional[str] = None


# === å·¥å…·å‡½æ•¸ ===

def get_timestamp() -> str:
    """å–å¾— UTC+8 æ™‚é–“æˆ³"""
    return datetime.now().strftime(f"%Y-%m-%dT%H:%M:%S{TZ_OFFSET}")


def load_config() -> Dict[str, Any]:
    """è¼‰å…¥é…ç½®æª”"""
    settings_file = CONFIG_DIR / "settings.yaml"
    if settings_file.exists():
        with open(settings_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f) or {}
    return {}


def load_rules() -> Dict[str, Any]:
    """è¼‰å…¥æ¼”é€²è¦å‰‡"""
    rules_file = CONFIG_DIR / "rules.yaml"
    if rules_file.exists():
        with open(rules_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f) or {}
    return {}


def load_logs(days: int = 7) -> List[Dict[str, Any]]:
    """è¼‰å…¥æœ€è¿‘ N å¤©çš„æ—¥èªŒ"""
    logs = []
    today = datetime.now()

    for i in range(days):
        date = today - timedelta(days=i)
        log_file = LOGS_DIR / f"{date.strftime('%Y-%m-%d')}.jsonl"

        if log_file.exists():
            with open(log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            logs.append(json.loads(line))
                        except json.JSONDecodeError:
                            continue

    return logs


def get_skill_list() -> List[str]:
    """å–å¾—æ‰€æœ‰ skill åç¨±"""
    skills = []
    for skill_dir in SKILLS_DIR.iterdir():
        if skill_dir.is_dir() and (skill_dir / "SKILL.md").exists():
            name = skill_dir.name
            if name not in ["_archived", "_shared"]:
                skills.append(name)
    return sorted(skills)


def read_skill_file(skill_name: str) -> Optional[str]:
    """è®€å– skill æª”æ¡ˆå…§å®¹"""
    skill_file = SKILLS_DIR / skill_name / "SKILL.md"
    if skill_file.exists():
        with open(skill_file, 'r', encoding='utf-8') as f:
            return f.read()
    return None


def parse_skill_frontmatter(content: str) -> Dict[str, Any]:
    """è§£æ skill frontmatter"""
    match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
    if match:
        try:
            return yaml.safe_load(match.group(1)) or {}
        except yaml.YAMLError:
            return {}
    return {}


def generate_proposal_id(skill_name: str) -> str:
    """ç”Ÿæˆææ¡ˆ ID"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    hash_suffix = hashlib.md5(f"{skill_name}{timestamp}".encode()).hexdigest()[:6]
    return f"{skill_name}-{hash_suffix}"


# === åˆ†æå‡½æ•¸ ===

def analyze_usage_patterns(logs: List[Dict], skills: List[str]) -> Dict[str, SkillMetrics]:
    """åˆ†æä½¿ç”¨æ¨¡å¼"""
    metrics = {skill: SkillMetrics(skill_name=skill) for skill in skills}

    for log in logs:
        # è·³éé dict é¡å‹çš„æ—¥èªŒé …
        if not isinstance(log, dict):
            continue

        skill = log.get('skill')
        if skill and skill in metrics:
            m = metrics[skill]
            action = log.get('action')

            if action == 'invoked':
                m.invocation_count += 1
                m.last_invoked = log.get('timestamp')

                result = log.get('result', 'success')
                if result == 'success':
                    m.success_count += 1
                else:
                    m.failure_count += 1
                    # è¨˜éŒ„éŒ¯èª¤æ¨¡å¼
                    error = log.get('error')
                    if error and error not in m.error_patterns:
                        m.error_patterns.append(error)

                # è¨˜éŒ„æŒçºŒæ™‚é–“
                duration = log.get('duration_ms', 0)
                if duration > 0:
                    total = m.avg_duration_ms * (m.invocation_count - 1) + duration
                    m.avg_duration_ms = total / m.invocation_count

            elif action == 'skipped':
                m.skip_count += 1
                reason = log.get('reason')
                if reason:
                    m.trigger_attempts.append(reason)

    return metrics


def identify_trigger_opportunities(metrics: Dict[str, SkillMetrics]) -> List[Dict]:
    """è­˜åˆ¥è§¸ç™¼è©æ”¹é€²æ©Ÿæœƒ"""
    opportunities = []

    for skill_name, m in metrics.items():
        # å¦‚æœæœ‰å¾ˆå¤šè·³éè¨˜éŒ„ï¼Œå¯èƒ½éœ€è¦æ”¹é€²è§¸ç™¼è©
        if m.skip_count > 3:
            opportunities.append({
                'skill': skill_name,
                'type': 'trigger_improvement',
                'level': 'patch',
                'reason': f"Skill è¢«è·³é {m.skip_count} æ¬¡",
                'attempts': m.trigger_attempts[:5]
            })

    return opportunities


def identify_error_patterns(metrics: Dict[str, SkillMetrics]) -> List[Dict]:
    """è­˜åˆ¥éŒ¯èª¤æ¨¡å¼"""
    opportunities = []

    for skill_name, m in metrics.items():
        # æˆåŠŸç‡ä½æ–¼ 70%
        if m.invocation_count >= 5 and m.success_rate < 70:
            opportunities.append({
                'skill': skill_name,
                'type': 'error_fix',
                'level': 'minor',
                'reason': f"æˆåŠŸç‡åƒ… {m.success_rate:.1f}%",
                'patterns': m.error_patterns[:3]
            })

    return opportunities


def identify_unused_skills(metrics: Dict[str, SkillMetrics], days: int) -> List[Dict]:
    """è­˜åˆ¥æœªä½¿ç”¨çš„ skills"""
    opportunities = []

    for skill_name, m in metrics.items():
        # åœ¨åˆ†ææœŸé–“å…§å®Œå…¨æœªä½¿ç”¨
        if m.invocation_count == 0:
            opportunities.append({
                'skill': skill_name,
                'type': 'unused',
                'level': 'major',
                'reason': f"éå» {days} å¤©æœªè¢«ä½¿ç”¨",
                'suggestion': 'è€ƒæ…®æ”¹é€²è§¸ç™¼è©æˆ–åˆä½µ/å»¢æ£„'
            })

    return opportunities


def analyze_skill_content(skill_name: str) -> List[Dict]:
    """åˆ†æ skill å…§å®¹å“è³ª"""
    opportunities = []
    content = read_skill_file(skill_name)

    if not content:
        return opportunities

    frontmatter = parse_skill_frontmatter(content)

    # æª¢æŸ¥å¿…è¦æ¬„ä½
    if 'description' not in frontmatter:
        opportunities.append({
            'skill': skill_name,
            'type': 'missing_description',
            'level': 'patch',
            'reason': 'ç¼ºå°‘ description æ¬„ä½'
        })

    # æª¢æŸ¥ evolution metadata
    if 'evolution' not in frontmatter:
        opportunities.append({
            'skill': skill_name,
            'type': 'missing_evolution_metadata',
            'level': 'patch',
            'reason': 'ç¼ºå°‘ evolution metadata'
        })

    # æª¢æŸ¥å¿…è¦ sections
    required_sections = ['Out of Scope', 'Verification', 'Integrations']
    for section in required_sections:
        if f"## {section}" not in content:
            opportunities.append({
                'skill': skill_name,
                'type': 'missing_section',
                'level': 'minor',
                'reason': f'ç¼ºå°‘ {section} section'
            })

    return opportunities


# === ææ¡ˆç”Ÿæˆ ===

def create_proposal(opportunity: Dict) -> EvolutionProposal:
    """æ ¹æ“šæ©Ÿæœƒå‰µå»ºææ¡ˆ"""
    skill_name = opportunity['skill']
    proposal_id = generate_proposal_id(skill_name)
    now = get_timestamp()
    expires = (datetime.now() + timedelta(days=7)).strftime(f"%Y-%m-%dT%H:%M:%S{TZ_OFFSET}")

    # æ ¹æ“šé¡å‹ç”Ÿæˆææ¡ˆå…§å®¹
    opp_type = opportunity['type']

    if opp_type == 'trigger_improvement':
        title = f"æ”¹é€² {skill_name} è§¸ç™¼è©"
        description = f"åˆ†æç™¼ç¾ {opportunity['reason']}ã€‚\nå»ºè­°å¯©æŸ¥ä¸¦æ–°å¢è§¸ç™¼è©ã€‚"
        changes = [{
            'file': 'SKILL.md',
            'type': 'review',
            'section': 'frontmatter.description',
            'note': 'å¯©æŸ¥è§¸ç™¼è©è¦†è“‹ç‡'
        }]

    elif opp_type == 'error_fix':
        title = f"ä¿®å¾© {skill_name} éŒ¯èª¤æ¨¡å¼"
        description = f"åˆ†æç™¼ç¾ {opportunity['reason']}ã€‚\nå¸¸è¦‹éŒ¯èª¤ï¼š{', '.join(opportunity.get('patterns', []))}"
        changes = [{
            'file': 'SKILL.md',
            'type': 'review',
            'section': 'workflow',
            'note': 'å¯©æŸ¥å·¥ä½œæµç¨‹å’ŒéŒ¯èª¤è™•ç†'
        }]

    elif opp_type == 'unused':
        title = f"å¯©æŸ¥æœªä½¿ç”¨çš„ {skill_name}"
        description = f"{opportunity['reason']}\n{opportunity.get('suggestion', '')}"
        changes = [{
            'file': 'SKILL.md',
            'type': 'review',
            'note': 'è€ƒæ…®æ”¹é€²ã€åˆä½µæˆ–å»¢æ£„'
        }]

    elif opp_type == 'missing_evolution_metadata':
        title = f"ç‚º {skill_name} æ–°å¢ evolution metadata"
        description = "æ­¤ skill ç¼ºå°‘ evolution metadataï¼Œç„¡æ³•åƒèˆ‡è‡ªå‹•æ¼”é€²ã€‚"
        changes = [{
            'file': 'SKILL.md',
            'type': 'edit',
            'section': 'frontmatter',
            'add': 'evolution: { enabled: true, version: "1.0.0", auto_evolve: patch }'
        }]

    elif opp_type == 'missing_section':
        section = opportunity['reason'].replace('ç¼ºå°‘ ', '').replace(' section', '')
        title = f"ç‚º {skill_name} æ–°å¢ {section} section"
        description = f"æ­¤ skill ç¼ºå°‘å»ºè­°çš„ {section} sectionã€‚"
        changes = [{
            'file': 'SKILL.md',
            'type': 'edit',
            'section': section,
            'note': f'æ–°å¢ ## {section}'
        }]

    else:
        title = f"{skill_name} æ”¹é€²ææ¡ˆ"
        description = opportunity.get('reason', 'éœ€è¦å¯©æŸ¥')
        changes = []

    impact = [opportunity.get('reason', 'æ”¹é€² skill å“è³ª')]

    return EvolutionProposal(
        proposal_id=proposal_id,
        skill_id=skill_name,
        created_at=now,
        expires_at=expires,
        change_level=opportunity.get('level', 'minor'),
        status='pending',
        source_type='session-analysis',
        source_session_id=None,
        source_trigger=opp_type,
        title=title,
        description=description,
        changes=changes,
        impact=impact
    )


def save_proposal(proposal: EvolutionProposal) -> Path:
    """å„²å­˜ææ¡ˆåˆ°æª”æ¡ˆ"""
    PENDING_DIR.mkdir(parents=True, exist_ok=True)

    proposal_file = PENDING_DIR / f"{proposal.proposal_id}.yaml"

    # è½‰æ›ç‚º dict
    data = asdict(proposal)

    with open(proposal_file, 'w', encoding='utf-8') as f:
        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, sort_keys=False)

    return proposal_file


# === å ±å‘Šç”Ÿæˆ ===

def generate_report(
    metrics: Dict[str, SkillMetrics],
    opportunities: List[Dict],
    proposals: List[EvolutionProposal],
    days: int
) -> str:
    """ç”Ÿæˆåˆ†æå ±å‘Š"""
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    week = datetime.now().strftime("%Y-W%W")

    report = f"""# Skill Evolution åˆ†æå ±å‘Š

**ç”Ÿæˆæ™‚é–“**: {now} (UTC+8)
**åˆ†ææœŸé–“**: éå» {days} å¤©
**å ±å‘Šé€±æœŸ**: {week}

---

## ä½¿ç”¨çµ±è¨ˆ

| Skill | èª¿ç”¨æ¬¡æ•¸ | æˆåŠŸç‡ | è·³éæ¬¡æ•¸ | æœ€å¾Œä½¿ç”¨ |
|-------|----------|--------|----------|----------|
"""

    # æŒ‰èª¿ç”¨æ¬¡æ•¸æ’åº
    sorted_metrics = sorted(metrics.values(), key=lambda m: m.invocation_count, reverse=True)

    for m in sorted_metrics[:20]:  # åªé¡¯ç¤ºå‰ 20 å€‹
        last = m.last_invoked[:10] if m.last_invoked else "N/A"
        report += f"| {m.skill_name} | {m.invocation_count} | {m.success_rate:.0f}% | {m.skip_count} | {last} |\n"

    report += f"""
---

## ç™¼ç¾çš„æ©Ÿæœƒ

å…±ç™¼ç¾ **{len(opportunities)}** å€‹æ”¹é€²æ©Ÿæœƒã€‚

### æŒ‰é¡å‹åˆ†é¡

"""

    # æŒ‰é¡å‹åˆ†çµ„
    by_type = defaultdict(list)
    for opp in opportunities:
        by_type[opp['type']].append(opp)

    type_names = {
        'trigger_improvement': 'è§¸ç™¼è©æ”¹é€²',
        'error_fix': 'éŒ¯èª¤ä¿®å¾©',
        'unused': 'æœªä½¿ç”¨ Skills',
        'missing_evolution_metadata': 'ç¼ºå°‘ Evolution Metadata',
        'missing_section': 'ç¼ºå°‘å¿…è¦ Section',
        'missing_description': 'ç¼ºå°‘ Description'
    }

    for opp_type, opps in by_type.items():
        type_name = type_names.get(opp_type, opp_type)
        report += f"#### {type_name} ({len(opps)} å€‹)\n\n"
        for opp in opps[:5]:
            report += f"- **{opp['skill']}**: {opp['reason']}\n"
        if len(opps) > 5:
            report += f"- ... é‚„æœ‰ {len(opps) - 5} å€‹\n"
        report += "\n"

    report += f"""---

## ç”Ÿæˆçš„ææ¡ˆ

å…±ç”Ÿæˆ **{len(proposals)}** å€‹æ¼”é€²ææ¡ˆã€‚

| ID | Skill | ç´šåˆ¥ | æ¨™é¡Œ |
|----|-------|------|------|
"""

    for p in proposals:
        level_emoji = {'patch': 'ğŸŸ¢', 'minor': 'ğŸŸ¡', 'major': 'ğŸ”´'}.get(p.change_level, 'âšª')
        report += f"| {p.proposal_id} | {p.skill_id} | {level_emoji} {p.change_level} | {p.title} |\n"

    report += f"""
---

## å»ºè­°è¡Œå‹•

1. **å¯©æŸ¥ Major ç´šåˆ¥ææ¡ˆ** - éœ€è¦æ‰‹å‹•ç¢ºèª
2. **ç­‰å¾… Minor ç´šåˆ¥ææ¡ˆ** - 24 å°æ™‚å¾Œè‡ªå‹•åŸ·è¡Œï¼ˆå¯å–æ¶ˆï¼‰
3. **Patch ç´šåˆ¥** - å·²è‡ªå‹•åŸ·è¡Œ

---

## ä¸‹ä¸€æ­¥

ææ¡ˆæª”æ¡ˆä½ç½®: `~/.claude/evolution/pending/`

åŸ·è¡Œå‘½ä»¤:
```bash
# æ‡‰ç”¨ patch ç´šåˆ¥æ›´æ–°
python3 ~/.claude/skills/skill-evolution/scripts/apply-update.py --level patch

# æŸ¥çœ‹æ‰€æœ‰å¾…è™•ç†ææ¡ˆ
ls ~/.claude/evolution/pending/
```

---

_å ±å‘Šç”± skill-evolution è‡ªå‹•ç”Ÿæˆ_
"""

    return report


def save_report(report: str) -> Path:
    """å„²å­˜å ±å‘Š"""
    REPORTS_DIR.mkdir(parents=True, exist_ok=True)

    week = datetime.now().strftime("%Y-W%W")
    report_file = REPORTS_DIR / f"weekly-{week}.md"

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)

    return report_file


# === ä¸»ç¨‹å¼ ===

def main():
    parser = argparse.ArgumentParser(
        description='Skill Evolution - æ©Ÿæœƒåˆ†æè…³æœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  python3 analyze-opportunities.py                    # åˆ†ææ‰€æœ‰ skills
  python3 analyze-opportunities.py --skill pine-lead  # åˆ†æç‰¹å®š skill
  python3 analyze-opportunities.py --days 14          # åˆ†ææœ€è¿‘ 14 å¤©
  python3 analyze-opportunities.py --report           # ç”Ÿæˆé€±å ±
  python3 analyze-opportunities.py --dry-run          # ä¹¾è·‘æ¨¡å¼
        """
    )

    parser.add_argument('--skill', type=str, help='åˆ†æç‰¹å®š skill')
    parser.add_argument('--days', type=int, default=7, help='åˆ†æå¤©æ•¸ (é è¨­: 7)')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆå ±å‘Š')
    parser.add_argument('--dry-run', action='store_true', help='ä¹¾è·‘æ¨¡å¼ï¼Œä¸å„²å­˜ææ¡ˆ')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')

    args = parser.parse_args()

    print(f"ğŸ” Skill Evolution åˆ†æå™¨")
    print(f"ğŸ“… åˆ†ææœŸé–“: éå» {args.days} å¤©")
    print()

    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    for d in [LOGS_DIR, PENDING_DIR, REPORTS_DIR, BACKUPS_DIR]:
        d.mkdir(parents=True, exist_ok=True)

    # è¼‰å…¥æ—¥èªŒ
    logs = load_logs(args.days)
    print(f"ğŸ“Š è¼‰å…¥ {len(logs)} æ¢æ—¥èªŒè¨˜éŒ„")

    # å–å¾— skill åˆ—è¡¨
    if args.skill:
        skills = [args.skill]
    else:
        skills = get_skill_list()
    print(f"ğŸ“¦ åˆ†æ {len(skills)} å€‹ skills")
    print()

    # åˆ†æä½¿ç”¨æ¨¡å¼
    print("ğŸ”„ åˆ†æä½¿ç”¨æ¨¡å¼...")
    metrics = analyze_usage_patterns(logs, skills)

    # è­˜åˆ¥æ©Ÿæœƒ
    opportunities = []

    print("ğŸ” è­˜åˆ¥è§¸ç™¼è©æ©Ÿæœƒ...")
    opportunities.extend(identify_trigger_opportunities(metrics))

    print("ğŸ” è­˜åˆ¥éŒ¯èª¤æ¨¡å¼...")
    opportunities.extend(identify_error_patterns(metrics))

    print("ğŸ” è­˜åˆ¥æœªä½¿ç”¨ skills...")
    opportunities.extend(identify_unused_skills(metrics, args.days))

    print("ğŸ” åˆ†æå…§å®¹å“è³ª...")
    for skill in skills:
        opportunities.extend(analyze_skill_content(skill))

    print(f"\nâœ… ç™¼ç¾ {len(opportunities)} å€‹æ”¹é€²æ©Ÿæœƒ")

    # ç”Ÿæˆææ¡ˆ
    proposals = []
    for opp in opportunities:
        proposal = create_proposal(opp)
        proposals.append(proposal)

        if not args.dry_run:
            save_proposal(proposal)
            if args.verbose:
                print(f"   ğŸ“ {proposal.proposal_id}: {proposal.title}")

    print(f"ğŸ“ ç”Ÿæˆ {len(proposals)} å€‹ææ¡ˆ")

    if args.dry_run:
        print("âš ï¸  ä¹¾è·‘æ¨¡å¼ - ææ¡ˆæœªå„²å­˜")

    # ç”Ÿæˆå ±å‘Š
    if args.report or not args.dry_run:
        print("\nğŸ“Š ç”Ÿæˆå ±å‘Š...")
        report = generate_report(metrics, opportunities, proposals, args.days)

        if not args.dry_run:
            report_file = save_report(report)
            print(f"ğŸ“„ å ±å‘Šå·²å„²å­˜: {report_file}")
        else:
            print("\n" + "=" * 60)
            print(report)
            print("=" * 60)

    print("\nâœ… åˆ†æå®Œæˆ")

    # è¼¸å‡ºæ‘˜è¦
    patch_count = sum(1 for p in proposals if p.change_level == 'patch')
    minor_count = sum(1 for p in proposals if p.change_level == 'minor')
    major_count = sum(1 for p in proposals if p.change_level == 'major')

    print(f"\nğŸ“Š ææ¡ˆæ‘˜è¦: ğŸŸ¢ {patch_count} patch | ğŸŸ¡ {minor_count} minor | ğŸ”´ {major_count} major")

    if not args.dry_run:
        print(f"\nğŸ“ ææ¡ˆä½ç½®: {PENDING_DIR}")


if __name__ == "__main__":
    main()
